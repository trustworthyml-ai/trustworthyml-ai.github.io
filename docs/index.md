# Trustworthy Machine Learning

Welcome to the comprehensive resource hub for **Trustworthy Machine Learning (TML)**. This site serves as a central repository for course materials, cutting-edge research, and community resources in the rapidly evolving field of trustworthy AI.

## What is Trustworthy ML?

Trustworthy Machine Learning encompasses the principles and practices needed to build AI systems that are:

- **Fair** and unbiased across different populations
- **Robust** to adversarial attacks and distribution shifts  
- **Transparent** and interpretable in their decision-making
- **Privacy-preserving** in how they handle sensitive data
- **Accountable** for their predictions and recommendations

## Course Overview

Our comprehensive course covers the fundamental concepts, state-of-the-art techniques, and practical implementations of trustworthy ML systems. Whether you're a student, researcher, or practitioner, you'll find valuable resources here.

!!! info "Fall 2024 Course"
    The Trustworthy ML course is being offered in Fall 2024. Check out the [syllabus](course/syllabus.md) for detailed information about topics, schedule, and assignments.

## Quick Navigation

=== "Students"
    - [Course Syllabus](course/syllabus.md)
    - [Schedule & Lectures](course/schedule.md)  
    - [Assignments](course/assignments.md)
    - [Project Guidelines](course/projects.md)

=== "Researchers"
    - [Paper Library](research/papers.md)
    - [Key Topics](research/topics.md)
    - [Recent Advances](research/recent.md)

=== "Practitioners"
    - [Tools & Frameworks](resources/tools.md)
    - [Datasets](resources/datasets.md)
    - [Tutorials](resources/tutorials.md)

## Featured Topics

- **Fairness in AI**: Bias detection, mitigation strategies, and fairness metrics
- **Adversarial Robustness**: Defense mechanisms and robust training techniques
- **Explainable AI**: Interpretability methods and transparency tools
- **Privacy-Preserving ML**: Differential privacy, federated learning, and secure computation
- **AI Safety**: Alignment, safety verification, and risk assessment

## Stay Connected

Join our growing community of researchers, practitioners, and students working on trustworthy AI:

- üêô [GitHub Organization](https://github.com/trustworthyml-ai)
- üê¶ [Twitter Updates](https://twitter.com/trustworthyml_ai)
- üí¨ [Community Discussions](community/discussion.md)
- üìÖ [Upcoming Events](community/events.md)

---

*This resource is continuously updated with the latest research, tools, and community contributions. [Contribute](community/contributing.md) to help us build the most comprehensive TML resource on the web.*