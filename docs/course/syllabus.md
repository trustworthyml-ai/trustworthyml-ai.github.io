# Course Syllabus: Trustworthy Machine Learning

## Course Information

**Course Title**: Trustworthy Machine Learning  
**Semester**: Fall 2024  
**Prerequisites**: Machine Learning fundamentals, Linear Algebra, Statistics, Python programming  
**Credits**: 3  

## Course Description

This course provides a comprehensive introduction to the principles, methods, and applications of trustworthy machine learning. Students will learn to design, implement, and evaluate ML systems that are fair, robust, transparent, privacy-preserving, and accountable. The course combines theoretical foundations with hands-on projects using real-world datasets and modern tools.

## Learning Objectives

By the end of this course, students will be able to:

1. **Understand Core Concepts**: Define and explain the key principles of trustworthy ML including fairness, robustness, interpretability, privacy, and accountability
2. **Identify Vulnerabilities**: Recognize potential sources of bias, adversarial attacks, and privacy leaks in ML systems
3. **Apply Mitigation Techniques**: Implement state-of-the-art methods for bias mitigation, adversarial defense, and privacy protection
4. **Evaluate Systems**: Use appropriate metrics and evaluation frameworks to assess the trustworthiness of ML models
5. **Design Solutions**: Architect end-to-end trustworthy ML systems for real-world applications

## Course Topics

### Module 1: Foundations (Weeks 1-3)
- Introduction to Trustworthy ML
- Ethics in AI and ML
- Legal and regulatory landscape
- Case studies of ML failures

### Module 2: Fairness & Bias (Weeks 4-6)
- Types of bias in ML systems
- Fairness definitions and metrics
- Pre-processing, in-processing, and post-processing techniques
- Intersectionality and group fairness

### Module 3: Robustness & Security (Weeks 7-9)
- Adversarial examples and attacks
- Certified defenses and robust training
- Distribution shift and domain adaptation
- Model stealing and membership inference attacks

### Module 4: Interpretability & Explainability (Weeks 10-11)
- Global vs. local interpretability
- Feature importance and attribution methods
- Counterfactual explanations
- Human-AI interaction and explanation quality

### Module 5: Privacy-Preserving ML (Weeks 12-13)
- Differential privacy fundamentals
- Federated learning
- Secure multi-party computation
- Privacy attacks and defenses

### Module 6: AI Safety & Alignment (Weeks 14-15)
- AI alignment problem
- Value learning and reward modeling
- Safety verification and testing
- Deployment considerations and monitoring

## Assessment

| Component | Weight | Description |
|-----------|--------|-------------|
| **Assignments (4)** | 40% | Individual coding and written assignments |
| **Midterm Exam** | 20% | In-class examination on Modules 1-3 |
| **Final Project** | 30% | Team-based research project with presentation |
| **Participation** | 10% | Class discussion, paper reviews, peer feedback |

### Assignment Schedule
- **Assignment 1**: Bias Detection and Mitigation (Week 5)
- **Assignment 2**: Adversarial Robustness (Week 8)  
- **Assignment 3**: Model Interpretability (Week 11)
- **Assignment 4**: Privacy-Preserving Techniques (Week 13)

### Final Project
Teams of 3-4 students will work on an original research project addressing a trustworthy ML challenge. Projects must include:
- Literature review and problem formulation
- Technical approach and implementation
- Experimental evaluation
- Written report (8-10 pages)
- Final presentation (15 minutes)

## Required Resources

### Textbooks
- *Fairness and Machine Learning* by Barocas, Hardt, and Narayanan (free online)
- *Interpretable Machine Learning* by Christoph Molnar (free online)

### Software & Tools
- Python 3.8+ with scikit-learn, PyTorch/TensorFlow
- Fairness toolkits: AIF360, Fairlearn
- Privacy libraries: Opacus, PySyft
- Interpretability tools: SHAP, LIME, Captum

### Computing Resources
- Google Colab Pro or similar cloud platform
- Course cluster access for larger experiments

## Policies

### Late Policy
- 10% penalty per day late
- Extensions granted for documented emergencies
- No late submissions accepted for final project

### Academic Integrity
All work must be original. Collaboration is encouraged on projects but must be clearly documented. Use of AI tools (ChatGPT, Copilot) must be disclosed and appropriately credited.

### Accessibility
Students with documented disabilities should contact the Office of Disability Services to arrange reasonable accommodations.

## Important Dates

- **Week 3**: Assignment 1 released
- **Week 6**: Midterm exam
- **Week 8**: Project proposal due
- **Week 12**: Project progress report
- **Week 15**: Final presentations
- **Finals Week**: Final project reports due

---

*This syllabus is subject to change with advance notice. Check the course website regularly for updates.*